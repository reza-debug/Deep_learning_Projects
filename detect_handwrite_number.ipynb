{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLv2e/9tqyurlPP5fY5OPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reza-debug/Deep_learning_Projects/blob/main/detect_handwrite_number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl2CoMtwrAjq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset ü§ô"
      ],
      "metadata": {
        "id": "rQNqtSowsm1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist"
      ],
      "metadata": {
        "id": "DTetKwXjriGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_features,train_labels) , (test_features,test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "aMZnFVfqr3ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape , test_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2ZHQe6GsSvO",
        "outputId": "a0bb6cc1-26a6-45ce-a7cf-087c9748648d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### see an example of dataset üòè\n"
      ],
      "metadata": {
        "id": "Jht4SnU2tCjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 138\n",
        "img = train_features[idx]\n",
        "print(train_labels[idx])\n",
        "\n",
        "plt.gray()\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "QodyymUIsdby",
        "outputId": "c089826a-dbe2-46ab-85fa-e4ea4ea433be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79c1db9056f0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing üßë"
      ],
      "metadata": {
        "id": "P5vktaYtu0OO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize (0-1) üåÑ"
      ],
      "metadata": {
        "id": "rwT3tCHDvXTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Cl4sILuTeE",
        "outputId": "b196bf4d-83c7-4160-b522-666d2f2ce697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  17,  79, 150, 255, 224,  29,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          9,  36, 135, 244, 253, 253, 253, 244,  45,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  73,\n",
              "        191, 253, 253, 253, 253, 247, 200,  94,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  57, 253,\n",
              "        253, 253, 253, 222, 177,  57,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 233, 253,\n",
              "        253, 226, 121,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 125, 253, 253,\n",
              "        145,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 196, 253,\n",
              "        251, 207,  81,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 233,\n",
              "        253, 253, 253, 100,  12,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,\n",
              "        176, 244, 253, 253, 144,  18,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 113, 253, 253, 253, 195,  21,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  18,  59, 200, 253, 253, 215,  54,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  18, 205, 253, 253, 194,  20,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  85, 209, 231, 231, 102,   0,\n",
              "          0,   0,   0,   0,  18, 206, 253, 253, 105,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 168, 252, 253, 248, 183,  55,   0,\n",
              "          0,   0,   0,   0,   0,  32, 253, 253, 170,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 171, 253, 253, 209,  21,   0,   0,\n",
              "          0,   0,   0,   0,   0,  44, 253, 253, 170,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 241, 253, 253, 152,  21,   0,\n",
              "          0,   0,   0,   0,  30, 217, 253, 241,  84,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  86, 241, 253, 253, 203,  66,\n",
              "         20,  20,  66,  66, 217, 253, 253, 103,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  85, 244, 253, 253, 253,\n",
              "        217, 217, 253, 253, 253, 244,  94,  15,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  31,  95, 253, 253,\n",
              "        253, 253, 253, 253, 201,  80,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  28, 135,\n",
              "        218, 217, 135,  28,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(img), np.max(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWBC0lZZurRx",
        "outputId": "26ad5c01-41b9-4605-e20b-ec9e795cab4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[138]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkgL3gIzyT1l",
        "outputId": "c9614fe7-4aa0-4b55-9d3a-56ed8eb5bb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  17,  79, 150, 255, 224,  29,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          9,  36, 135, 244, 253, 253, 253, 244,  45,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  73,\n",
              "        191, 253, 253, 253, 253, 247, 200,  94,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  57, 253,\n",
              "        253, 253, 253, 222, 177,  57,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 233, 253,\n",
              "        253, 226, 121,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 125, 253, 253,\n",
              "        145,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 196, 253,\n",
              "        251, 207,  81,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 233,\n",
              "        253, 253, 253, 100,  12,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,\n",
              "        176, 244, 253, 253, 144,  18,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 113, 253, 253, 253, 195,  21,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  18,  59, 200, 253, 253, 215,  54,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  18, 205, 253, 253, 194,  20,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  85, 209, 231, 231, 102,   0,\n",
              "          0,   0,   0,   0,  18, 206, 253, 253, 105,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 168, 252, 253, 248, 183,  55,   0,\n",
              "          0,   0,   0,   0,   0,  32, 253, 253, 170,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 171, 253, 253, 209,  21,   0,   0,\n",
              "          0,   0,   0,   0,   0,  44, 253, 253, 170,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 241, 253, 253, 152,  21,   0,\n",
              "          0,   0,   0,   0,  30, 217, 253, 241,  84,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  86, 241, 253, 253, 203,  66,\n",
              "         20,  20,  66,  66, 217, 253, 253, 103,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  85, 244, 253, 253, 253,\n",
              "        217, 217, 253, 253, 253, 244,  94,  15,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  31,  95, 253, 253,\n",
              "        253, 253, 253, 253, 201,  80,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  28, 135,\n",
              "        218, 217, 135,  28,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just devide to 255 all data by float-->.0\n",
        "train_features = train_features/255.0\n",
        "test_features = test_features/255.0"
      ],
      "metadata": {
        "id": "lZavOuLBvwtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[138]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbr2dLfawQX2",
        "outputId": "2f21bffc-5740-4fb7-f52a-23d19e3cded9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.06666667, 0.30980392, 0.58823529, 1.        ,\n",
              "        0.87843137, 0.11372549, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.14117647,\n",
              "        0.52941176, 0.95686275, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.95686275, 0.17647059, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.28627451, 0.74901961, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.96862745, 0.78431373,\n",
              "        0.36862745, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.22352941, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.87058824, 0.69411765, 0.22352941, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.4       , 0.91372549, 0.99215686, 0.99215686, 0.88627451,\n",
              "        0.4745098 , 0.10196078, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.49019608, 0.99215686, 0.99215686, 0.56862745, 0.07843137,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03529412, 0.76862745, 0.99215686, 0.98431373, 0.81176471,\n",
              "        0.31764706, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.08627451, 0.91372549, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.39215686, 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.0627451 , 0.69019608, 0.95686275,\n",
              "        0.99215686, 0.99215686, 0.56470588, 0.07058824, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.44313725,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.08235294,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.23137255, 0.78431373, 0.99215686, 0.99215686, 0.84313725,\n",
              "        0.21176471, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.80392157, 0.99215686, 0.99215686,\n",
              "        0.76078431, 0.07843137, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.33333333, 0.81960784, 0.90588235,\n",
              "        0.90588235, 0.4       , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.80784314, 0.99215686,\n",
              "        0.99215686, 0.41176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.65882353, 0.98823529, 0.99215686, 0.97254902,\n",
              "        0.71764706, 0.21568627, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.1254902 , 0.99215686,\n",
              "        0.99215686, 0.66666667, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.67058824, 0.99215686, 0.99215686, 0.81960784,\n",
              "        0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.17254902, 0.99215686,\n",
              "        0.99215686, 0.66666667, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.33333333, 0.94509804, 0.99215686, 0.99215686,\n",
              "        0.59607843, 0.08235294, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.11764706, 0.85098039, 0.99215686,\n",
              "        0.94509804, 0.32941176, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.3372549 , 0.94509804, 0.99215686,\n",
              "        0.99215686, 0.79607843, 0.25882353, 0.07843137, 0.07843137,\n",
              "        0.25882353, 0.25882353, 0.85098039, 0.99215686, 0.99215686,\n",
              "        0.40392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.33333333, 0.95686275,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.85098039, 0.85098039,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.95686275, 0.36862745,\n",
              "        0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.12156863,\n",
              "        0.37254902, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.78823529, 0.31372549, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.10980392, 0.52941176, 0.85490196, 0.85098039,\n",
              "        0.52941176, 0.10980392, 0.03529412, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QAJIERxxU7v",
        "outputId": "cb2e7afe-b937-4fff-c44b-6fa1c8a05b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  17,  79, 150, 255, 224,  29,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          9,  36, 135, 244, 253, 253, 253, 244,  45,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,  73,\n",
              "        191, 253, 253, 253, 253, 247, 200,  94,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  57, 253,\n",
              "        253, 253, 253, 222, 177,  57,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 233, 253,\n",
              "        253, 226, 121,  26,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 125, 253, 253,\n",
              "        145,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 196, 253,\n",
              "        251, 207,  81,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22, 233,\n",
              "        253, 253, 253, 100,  12,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  16,\n",
              "        176, 244, 253, 253, 144,  18,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 113, 253, 253, 253, 195,  21,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  18,  59, 200, 253, 253, 215,  54,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  18, 205, 253, 253, 194,  20,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  85, 209, 231, 231, 102,   0,\n",
              "          0,   0,   0,   0,  18, 206, 253, 253, 105,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 168, 252, 253, 248, 183,  55,   0,\n",
              "          0,   0,   0,   0,   0,  32, 253, 253, 170,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 171, 253, 253, 209,  21,   0,   0,\n",
              "          0,   0,   0,   0,   0,  44, 253, 253, 170,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 241, 253, 253, 152,  21,   0,\n",
              "          0,   0,   0,   0,  30, 217, 253, 241,  84,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  86, 241, 253, 253, 203,  66,\n",
              "         20,  20,  66,  66, 217, 253, 253, 103,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  85, 244, 253, 253, 253,\n",
              "        217, 217, 253, 253, 253, 244,  94,  15,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  31,  95, 253, 253,\n",
              "        253, 253, 253, 253, 201,  80,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  28, 135,\n",
              "        218, 217, 135,  28,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Difinition üèõ"
      ],
      "metadata": {
        "id": "SynU5s6MUW_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "#flatten for flat matrix of picture\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(units=128,activation='relu'))\n",
        "model.add(keras.layers.Dense(units=128,activation='relu'))\n",
        "#10 class so 10 noron\n",
        "#softmax for ditect max output\n",
        "model.add(keras.layers.Dense(units=10,activation='Softmax'))"
      ],
      "metadata": {
        "id": "vSsLBsC6yLZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile üêæ"
      ],
      "metadata": {
        "id": "vnOINXPvcfRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),loss= tf.losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DWDnzF6IV9Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fix inpute shape üëø"
      ],
      "metadata": {
        "id": "8NiIuV32gGEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#None for first flat layer and 28*28 for other layer\n",
        "#if do not that with build or in first layer can't show summary of model\n",
        "model.build(input_shape=(None,28,28))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj6sdpkSflej",
        "outputId": "226ce997-e067-4208-8348-6770cf317f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118282 (462.04 KB)\n",
            "Trainable params: 118282 (462.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train_features,train_labels, epochs=1000, batch_size=256, validation_data=(test_features,test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibcv3SWvhE4m",
        "outputId": "3f50649e-d530-4de0-e466-e9bbe817e9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "235/235 [==============================] - 4s 5ms/step - loss: 0.4035 - accuracy: 0.8898 - val_loss: 0.1861 - val_accuracy: 0.9451\n",
            "Epoch 2/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1550 - accuracy: 0.9556 - val_loss: 0.1315 - val_accuracy: 0.9614\n",
            "Epoch 3/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9677 - val_loss: 0.1034 - val_accuracy: 0.9694\n",
            "Epoch 4/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9745 - val_loss: 0.0858 - val_accuracy: 0.9745\n",
            "Epoch 5/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9807 - val_loss: 0.0858 - val_accuracy: 0.9745\n",
            "Epoch 6/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9844 - val_loss: 0.0785 - val_accuracy: 0.9762\n",
            "Epoch 7/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 0.0771 - val_accuracy: 0.9759\n",
            "Epoch 8/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.0754 - val_accuracy: 0.9765\n",
            "Epoch 9/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.0794 - val_accuracy: 0.9770\n",
            "Epoch 10/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.0757 - val_accuracy: 0.9786\n",
            "Epoch 11/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
            "Epoch 12/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0735 - val_accuracy: 0.9800\n",
            "Epoch 13/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.0849 - val_accuracy: 0.9764\n",
            "Epoch 14/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.0762 - val_accuracy: 0.9782\n",
            "Epoch 15/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0950 - val_accuracy: 0.9763\n",
            "Epoch 16/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0823 - val_accuracy: 0.9782\n",
            "Epoch 17/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0965 - val_accuracy: 0.9769\n",
            "Epoch 18/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.0803 - val_accuracy: 0.9814\n",
            "Epoch 19/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0854 - val_accuracy: 0.9802\n",
            "Epoch 20/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0819 - val_accuracy: 0.9787\n",
            "Epoch 21/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0883 - val_accuracy: 0.9803\n",
            "Epoch 22/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0847 - val_accuracy: 0.9805\n",
            "Epoch 23/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1026 - val_accuracy: 0.9762\n",
            "Epoch 24/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
            "Epoch 25/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0952 - val_accuracy: 0.9796\n",
            "Epoch 26/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0911 - val_accuracy: 0.9794\n",
            "Epoch 27/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1081 - val_accuracy: 0.9777\n",
            "Epoch 28/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0976 - val_accuracy: 0.9806\n",
            "Epoch 29/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0970 - val_accuracy: 0.9797\n",
            "Epoch 30/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.1025 - val_accuracy: 0.9803\n",
            "Epoch 31/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7587e-04 - accuracy: 0.9999 - val_loss: 0.0977 - val_accuracy: 0.9804\n",
            "Epoch 32/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.2127e-04 - accuracy: 0.9999 - val_loss: 0.1079 - val_accuracy: 0.9787\n",
            "Epoch 33/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1200 - val_accuracy: 0.9762\n",
            "Epoch 34/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.1104 - val_accuracy: 0.9772\n",
            "Epoch 35/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1037 - val_accuracy: 0.9819\n",
            "Epoch 36/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1039 - val_accuracy: 0.9820\n",
            "Epoch 37/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.1474e-04 - accuracy: 0.9999 - val_loss: 0.1006 - val_accuracy: 0.9821\n",
            "Epoch 38/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.8008e-04 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9817\n",
            "Epoch 39/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4717e-04 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9813\n",
            "Epoch 40/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0989e-04 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9817\n",
            "Epoch 41/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.4307e-05 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9814\n",
            "Epoch 42/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.3152e-05 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9818\n",
            "Epoch 43/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.4694e-05 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9814\n",
            "Epoch 44/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7657e-05 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9818\n",
            "Epoch 45/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.1022e-05 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9817\n",
            "Epoch 46/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5607e-05 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9819\n",
            "Epoch 47/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.1278e-05 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9821\n",
            "Epoch 48/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.5885e-05 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9817\n",
            "Epoch 49/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2239e-05 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9814\n",
            "Epoch 50/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.8669e-05 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9819\n",
            "Epoch 51/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.4975e-05 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9815\n",
            "Epoch 52/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1915e-05 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9818\n",
            "Epoch 53/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9070e-05 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9815\n",
            "Epoch 54/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7014e-05 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9816\n",
            "Epoch 55/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5299e-05 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9813\n",
            "Epoch 56/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2084e-05 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9819\n",
            "Epoch 57/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0279e-05 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9815\n",
            "Epoch 58/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7889e-05 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9812\n",
            "Epoch 59/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6651e-05 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9813\n",
            "Epoch 60/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4982e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9815\n",
            "Epoch 61/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3564e-05 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9819\n",
            "Epoch 62/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2237e-05 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9815\n",
            "Epoch 63/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1113e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9812\n",
            "Epoch 64/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.0535e-05 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9816\n",
            "Epoch 65/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.3753e-06 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9813\n",
            "Epoch 66/1000\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 8.1657e-06 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9813\n",
            "Epoch 67/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.2807 - val_accuracy: 0.9605\n",
            "Epoch 68/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9892 - val_loss: 0.1084 - val_accuracy: 0.9795\n",
            "Epoch 69/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1138 - val_accuracy: 0.9801\n",
            "Epoch 70/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1124 - val_accuracy: 0.9803\n",
            "Epoch 71/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9990e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9822\n",
            "Epoch 72/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4922e-04 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9818\n",
            "Epoch 73/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1384e-04 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9813\n",
            "Epoch 74/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.5489e-05 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9817\n",
            "Epoch 75/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.1868e-05 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9818\n",
            "Epoch 76/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.1237e-05 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9818\n",
            "Epoch 77/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.2157e-05 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9814\n",
            "Epoch 78/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5031e-05 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9818\n",
            "Epoch 79/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.9008e-05 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9817\n",
            "Epoch 80/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.3434e-05 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9816\n",
            "Epoch 81/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.8888e-05 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9818\n",
            "Epoch 82/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4995e-05 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9817\n",
            "Epoch 83/1000\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 3.0956e-05 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9819\n",
            "Epoch 84/1000\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 2.7988e-05 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9817\n",
            "Epoch 85/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5069e-05 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9816\n",
            "Epoch 86/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2404e-05 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9813\n",
            "Epoch 87/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.0320e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9817\n",
            "Epoch 88/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8123e-05 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9814\n",
            "Epoch 89/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6397e-05 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9816\n",
            "Epoch 90/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4593e-05 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9818\n",
            "Epoch 91/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3051e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9811\n",
            "Epoch 92/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2063e-05 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9812\n",
            "Epoch 93/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0593e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9811\n",
            "Epoch 94/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.6002e-06 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9810\n",
            "Epoch 95/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.8334e-06 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9812\n",
            "Epoch 96/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.8653e-06 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9812\n",
            "Epoch 97/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.0361e-06 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9809\n",
            "Epoch 98/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.5047e-06 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9811\n",
            "Epoch 99/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.6979e-06 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9810\n",
            "Epoch 100/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 5.0882e-06 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9811\n",
            "Epoch 101/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.5966e-06 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9809\n",
            "Epoch 102/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0836e-06 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9809\n",
            "Epoch 103/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7225e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9813\n",
            "Epoch 104/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3673e-06 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9813\n",
            "Epoch 105/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9550e-06 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9814\n",
            "Epoch 106/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6555e-06 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9812\n",
            "Epoch 107/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3511e-06 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9814\n",
            "Epoch 108/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1338e-06 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9811\n",
            "Epoch 109/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9132e-06 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9812\n",
            "Epoch 110/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7526e-06 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9812\n",
            "Epoch 111/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5294e-06 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9812\n",
            "Epoch 112/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.3781e-06 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9811\n",
            "Epoch 113/1000\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 1.2082e-06 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9813\n",
            "Epoch 114/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.0837e-06 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9816\n",
            "Epoch 115/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.5326e-07 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9813\n",
            "Epoch 116/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.6482e-07 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9812\n",
            "Epoch 117/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.9474e-07 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9813\n",
            "Epoch 118/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.0073e-07 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9809\n",
            "Epoch 119/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.1065e-07 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9813\n",
            "Epoch 120/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.9978e-07 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9812\n",
            "Epoch 121/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.0415e-07 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9811\n",
            "Epoch 122/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.3258e-07 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9811\n",
            "Epoch 123/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.8774e-07 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9809\n",
            "Epoch 124/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4174e-07 - accuracy: 1.0000 - val_loss: 0.1583 - val_accuracy: 0.9811\n",
            "Epoch 125/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.0999e-07 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9811\n",
            "Epoch 126/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7484e-07 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9811\n",
            "Epoch 127/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.4732e-07 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9810\n",
            "Epoch 128/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2032e-07 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9813\n",
            "Epoch 129/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9613e-07 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 0.9811\n",
            "Epoch 130/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7372e-07 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9812\n",
            "Epoch 131/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5710e-07 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9811\n",
            "Epoch 132/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3838e-07 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9812\n",
            "Epoch 133/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2721e-07 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9812\n",
            "Epoch 134/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1429e-07 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9814\n",
            "Epoch 135/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0108e-07 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9810\n",
            "Epoch 136/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.0249e-08 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9810\n",
            "Epoch 137/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.0736e-08 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9810\n",
            "Epoch 138/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.3324e-08 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9812\n",
            "Epoch 139/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.5196e-08 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9812\n",
            "Epoch 140/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.8581e-08 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9811\n",
            "Epoch 141/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.3672e-08 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9811\n",
            "Epoch 142/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.6988e-08 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9810\n",
            "Epoch 143/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.3160e-08 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9813\n",
            "Epoch 144/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0052e-08 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9812\n",
            "Epoch 145/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4952e-08 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9812\n",
            "Epoch 146/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2707e-08 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9809\n",
            "Epoch 147/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9449e-08 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9813\n",
            "Epoch 148/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7231e-08 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9810\n",
            "Epoch 149/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4498e-08 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9812\n",
            "Epoch 150/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2691e-08 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9810\n",
            "Epoch 151/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.0762e-08 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9812\n",
            "Epoch 152/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.8539e-08 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9814\n",
            "Epoch 153/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.7293e-08 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9810\n",
            "Epoch 154/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.5684e-08 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9814\n",
            "Epoch 155/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4500e-08 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9810\n",
            "Epoch 156/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3433e-08 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9811\n",
            "Epoch 157/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2539e-08 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9813\n",
            "Epoch 158/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1524e-08 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9810\n",
            "Epoch 159/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0830e-08 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9814\n",
            "Epoch 160/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.9917e-09 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9812\n",
            "Epoch 161/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.3341e-09 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9809\n",
            "Epoch 162/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.8493e-09 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9813\n",
            "Epoch 163/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.3625e-09 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9810\n",
            "Epoch 164/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.7824e-09 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9807\n",
            "Epoch 165/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.3810e-09 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9811\n",
            "Epoch 166/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.9598e-09 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9811\n",
            "Epoch 167/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.5863e-09 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9812\n",
            "Epoch 168/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.2625e-09 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9811\n",
            "Epoch 169/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.8949e-09 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9811\n",
            "Epoch 170/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.6108e-09 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9811\n",
            "Epoch 171/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.3366e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9810\n",
            "Epoch 172/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.1677e-09 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9810\n",
            "Epoch 173/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.8478e-09 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9813\n",
            "Epoch 174/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.6492e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9809\n",
            "Epoch 175/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.4624e-09 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9810\n",
            "Epoch 176/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.3452e-09 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9810\n",
            "Epoch 177/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1584e-09 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9809\n",
            "Epoch 178/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.9776e-09 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9809\n",
            "Epoch 179/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.8465e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9809\n",
            "Epoch 180/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7491e-09 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9811\n",
            "Epoch 181/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5524e-09 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9809\n",
            "Epoch 182/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4054e-09 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9810\n",
            "Epoch 183/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3617e-09 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9809\n",
            "Epoch 184/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2306e-09 - accuracy: 1.0000 - val_loss: 0.2038 - val_accuracy: 0.9810\n",
            "Epoch 185/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1133e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9811\n",
            "Epoch 186/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0160e-09 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9809\n",
            "Epoch 187/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9624e-09 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9810\n",
            "Epoch 188/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8531e-09 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9809\n",
            "Epoch 189/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.8392e-09 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9810\n",
            "Epoch 190/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7239e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9810\n",
            "Epoch 191/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.6266e-09 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9812\n",
            "Epoch 192/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5769e-09 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9810\n",
            "Epoch 193/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5570e-09 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9811\n",
            "Epoch 194/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4676e-09 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9810\n",
            "Epoch 195/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4100e-09 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9810\n",
            "Epoch 196/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3146e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9810\n",
            "Epoch 197/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3544e-09 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9810\n",
            "Epoch 198/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2809e-09 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9811\n",
            "Epoch 199/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2610e-09 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9811\n",
            "Epoch 200/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2173e-09 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9810\n",
            "Epoch 201/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1636e-09 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9810\n",
            "Epoch 202/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1279e-09 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9811\n",
            "Epoch 203/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.1100e-09 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9812\n",
            "Epoch 204/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1021e-09 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9812\n",
            "Epoch 205/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0325e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9812\n",
            "Epoch 206/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0583e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9811\n",
            "Epoch 207/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0067e-09 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9811\n",
            "Epoch 208/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9987e-09 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9810\n",
            "Epoch 209/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9610e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9811\n",
            "Epoch 210/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9530e-09 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9811\n",
            "Epoch 211/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9093e-09 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9812\n",
            "Epoch 212/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9073e-09 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9811\n",
            "Epoch 213/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8795e-09 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9811\n",
            "Epoch 214/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8756e-09 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9811\n",
            "Epoch 215/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8517e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9811\n",
            "Epoch 216/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8716e-09 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9811\n",
            "Epoch 217/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8418e-09 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9810\n",
            "Epoch 218/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8597e-09 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9811\n",
            "Epoch 219/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8438e-09 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9811\n",
            "Epoch 220/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8736e-09 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9809\n",
            "Epoch 221/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8398e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9811\n",
            "Epoch 222/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7901e-09 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9810\n",
            "Epoch 223/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9810\n",
            "Epoch 224/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7504e-09 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9810\n",
            "Epoch 225/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8020e-09 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9811\n",
            "Epoch 226/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8080e-09 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9809\n",
            "Epoch 227/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7643e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9811\n",
            "Epoch 228/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.7921e-09 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9810\n",
            "Epoch 229/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.7405e-09 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9811\n",
            "Epoch 230/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.7842e-09 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9811\n",
            "Epoch 231/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7822e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9813\n",
            "Epoch 232/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7643e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9812\n",
            "Epoch 233/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9812\n",
            "Epoch 234/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7544e-09 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9812\n",
            "Epoch 235/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7703e-09 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9811\n",
            "Epoch 236/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8001e-09 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9809\n",
            "Epoch 237/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8160e-09 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9810\n",
            "Epoch 238/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7822e-09 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9810\n",
            "Epoch 239/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7762e-09 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9810\n",
            "Epoch 240/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7802e-09 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9810\n",
            "Epoch 241/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8140e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9809\n",
            "Epoch 242/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8299e-09 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9811\n",
            "Epoch 243/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8160e-09 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9811\n",
            "Epoch 244/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8239e-09 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9809\n",
            "Epoch 245/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9809\n",
            "Epoch 246/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7901e-09 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9809\n",
            "Epoch 247/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9810\n",
            "Epoch 248/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8140e-09 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9809\n",
            "Epoch 249/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8318e-09 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9809\n",
            "Epoch 250/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8597e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9808\n",
            "Epoch 251/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8398e-09 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9810\n",
            "Epoch 252/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8636e-09 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9810\n",
            "Epoch 253/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8815e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9810\n",
            "Epoch 254/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8597e-09 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9809\n",
            "Epoch 255/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8458e-09 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9809\n",
            "Epoch 256/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8458e-09 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9808\n",
            "Epoch 257/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8895e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9808\n",
            "Epoch 258/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8557e-09 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9808\n",
            "Epoch 259/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8358e-09 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9810\n",
            "Epoch 260/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8994e-09 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9809\n",
            "Epoch 261/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9808\n",
            "Epoch 262/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9034e-09 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9808\n",
            "Epoch 263/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9173e-09 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9809\n",
            "Epoch 264/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8875e-09 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9808\n",
            "Epoch 265/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8517e-09 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9808\n",
            "Epoch 266/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.8934e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9809\n",
            "Epoch 267/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9352e-09 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9809\n",
            "Epoch 268/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.9689e-09 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9809\n",
            "Epoch 269/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.9133e-09 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9809\n",
            "Epoch 270/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9810\n",
            "Epoch 271/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9292e-09 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9811\n",
            "Epoch 272/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9252e-09 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9807\n",
            "Epoch 273/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9888e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9807\n",
            "Epoch 274/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9352e-09 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9810\n",
            "Epoch 275/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9749e-09 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9807\n",
            "Epoch 276/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9809e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9806\n",
            "Epoch 277/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9729e-09 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9806\n",
            "Epoch 278/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9968e-09 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9806\n",
            "Epoch 279/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9789e-09 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9806\n",
            "Epoch 280/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0146e-09 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9805\n",
            "Epoch 281/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.0246e-09 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9807\n",
            "Epoch 282/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.0305e-09 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9807\n",
            "Epoch 283/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.0643e-09 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9807\n",
            "Epoch 284/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0365e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9805\n",
            "Epoch 285/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9908e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9808\n",
            "Epoch 286/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0246e-09 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9805\n",
            "Epoch 287/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0782e-09 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9807\n",
            "Epoch 288/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0742e-09 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9806\n",
            "Epoch 289/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0842e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9805\n",
            "Epoch 290/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1358e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9804\n",
            "Epoch 291/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0782e-09 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9807\n",
            "Epoch 292/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0981e-09 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9806\n",
            "Epoch 293/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1219e-09 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9804\n",
            "Epoch 294/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1994e-09 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9804\n",
            "Epoch 295/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1140e-09 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9804\n",
            "Epoch 296/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1398e-09 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9804\n",
            "Epoch 297/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1537e-09 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9807\n",
            "Epoch 298/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1835e-09 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9806\n",
            "Epoch 299/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2332e-09 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9808\n",
            "Epoch 300/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1875e-09 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9809\n",
            "Epoch 301/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2034e-09 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9807\n",
            "Epoch 302/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1319e-09 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9805\n",
            "Epoch 303/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2113e-09 - accuracy: 1.0000 - val_loss: 0.2350 - val_accuracy: 0.9804\n",
            "Epoch 304/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2689e-09 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9806\n",
            "Epoch 305/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2213e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9805\n",
            "Epoch 306/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2034e-09 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9804\n",
            "Epoch 307/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2769e-09 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9803\n",
            "Epoch 308/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.2531e-09 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9800\n",
            "Epoch 309/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2968e-09 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9801\n",
            "Epoch 310/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2590e-09 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9798\n",
            "Epoch 311/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3524e-09 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9800\n",
            "Epoch 312/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3067e-09 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9801\n",
            "Epoch 313/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3385e-09 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9800\n",
            "Epoch 314/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3743e-09 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9803\n",
            "Epoch 315/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3683e-09 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9801\n",
            "Epoch 316/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4855e-09 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9802\n",
            "Epoch 317/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4478e-09 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9797\n",
            "Epoch 318/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4458e-09 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9798\n",
            "Epoch 319/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4319e-09 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9800\n",
            "Epoch 320/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4676e-09 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9799\n",
            "Epoch 321/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.5272e-09 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9798\n",
            "Epoch 322/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5094e-09 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9799\n",
            "Epoch 323/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4736e-09 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9801\n",
            "Epoch 324/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5551e-09 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9802\n",
            "Epoch 325/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5133e-09 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9801\n",
            "Epoch 326/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5908e-09 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9802\n",
            "Epoch 327/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.5372e-09 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9802\n",
            "Epoch 328/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6186e-09 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9799\n",
            "Epoch 329/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6445e-09 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9800\n",
            "Epoch 330/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6246e-09 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9796\n",
            "Epoch 331/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7021e-09 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9801\n",
            "Epoch 332/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7080e-09 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9799\n",
            "Epoch 333/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7498e-09 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9800\n",
            "Epoch 334/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7557e-09 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9798\n",
            "Epoch 335/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7557e-09 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9799\n",
            "Epoch 336/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8531e-09 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9799\n",
            "Epoch 337/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7577e-09 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9797\n",
            "Epoch 338/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8531e-09 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9802\n",
            "Epoch 339/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7557e-09 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9800\n",
            "Epoch 340/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9822e-09 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9800\n",
            "Epoch 341/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9306e-09 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9800\n",
            "Epoch 342/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9167e-09 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9799\n",
            "Epoch 343/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9544e-09 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9799\n",
            "Epoch 344/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.8749e-09 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9798\n",
            "Epoch 345/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.9405e-09 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9800\n",
            "Epoch 346/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.1332e-09 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9802\n",
            "Epoch 347/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8888e-09 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9796\n",
            "Epoch 348/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0299e-09 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9799\n",
            "Epoch 349/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2504e-09 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9795\n",
            "Epoch 350/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0279e-09 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9797\n",
            "Epoch 351/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9902e-09 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9796\n",
            "Epoch 352/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9984 - val_loss: 0.6725 - val_accuracy: 0.9577\n",
            "Epoch 353/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9914 - val_loss: 0.2641 - val_accuracy: 0.9782\n",
            "Epoch 354/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.2291 - val_accuracy: 0.9803\n",
            "Epoch 355/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.2304 - val_accuracy: 0.9791\n",
            "Epoch 356/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.9872e-04 - accuracy: 0.9997 - val_loss: 0.2226 - val_accuracy: 0.9806\n",
            "Epoch 357/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.2197 - val_accuracy: 0.9801\n",
            "Epoch 358/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.2321 - val_accuracy: 0.9797\n",
            "Epoch 359/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.2414 - val_accuracy: 0.9803\n",
            "Epoch 360/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2558 - val_accuracy: 0.9766\n",
            "Epoch 361/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.2619 - val_accuracy: 0.9769\n",
            "Epoch 362/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.2455 - val_accuracy: 0.9775\n",
            "Epoch 363/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.2583 - val_accuracy: 0.9788\n",
            "Epoch 364/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2096 - val_accuracy: 0.9806\n",
            "Epoch 365/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.2243 - val_accuracy: 0.9799\n",
            "Epoch 366/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.2429 - val_accuracy: 0.9782\n",
            "Epoch 367/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.2247 - val_accuracy: 0.9781\n",
            "Epoch 368/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2036 - val_accuracy: 0.9803\n",
            "Epoch 369/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.2544 - val_accuracy: 0.9775\n",
            "Epoch 370/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.2263 - val_accuracy: 0.9789\n",
            "Epoch 371/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.2230 - val_accuracy: 0.9781\n",
            "Epoch 372/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.2053 - val_accuracy: 0.9787\n",
            "Epoch 373/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.2342 - val_accuracy: 0.9772\n",
            "Epoch 374/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2217 - val_accuracy: 0.9794\n",
            "Epoch 375/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.2139 - val_accuracy: 0.9790\n",
            "Epoch 376/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2202 - val_accuracy: 0.9784\n",
            "Epoch 377/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2148 - val_accuracy: 0.9803\n",
            "Epoch 378/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.2154 - val_accuracy: 0.9791\n",
            "Epoch 379/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.2162 - val_accuracy: 0.9782\n",
            "Epoch 380/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.2151 - val_accuracy: 0.9810\n",
            "Epoch 381/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.2230 - val_accuracy: 0.9794\n",
            "Epoch 382/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2180 - val_accuracy: 0.9781\n",
            "Epoch 383/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.2281 - val_accuracy: 0.9781\n",
            "Epoch 384/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.2498 - val_accuracy: 0.9780\n",
            "Epoch 385/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.2281 - val_accuracy: 0.9770\n",
            "Epoch 386/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.2259 - val_accuracy: 0.9790\n",
            "Epoch 387/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.2205 - val_accuracy: 0.9792\n",
            "Epoch 388/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2152 - val_accuracy: 0.9806\n",
            "Epoch 389/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.6930e-04 - accuracy: 0.9998 - val_loss: 0.2069 - val_accuracy: 0.9807\n",
            "Epoch 390/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.2441 - val_accuracy: 0.9784\n",
            "Epoch 391/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.2288 - val_accuracy: 0.9799\n",
            "Epoch 392/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.2686 - val_accuracy: 0.9757\n",
            "Epoch 393/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.2184 - val_accuracy: 0.9798\n",
            "Epoch 394/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.2310 - val_accuracy: 0.9786\n",
            "Epoch 395/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.8348e-04 - accuracy: 0.9997 - val_loss: 0.2102 - val_accuracy: 0.9810\n",
            "Epoch 396/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.0765e-04 - accuracy: 0.9999 - val_loss: 0.2143 - val_accuracy: 0.9802\n",
            "Epoch 397/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.8829e-04 - accuracy: 0.9998 - val_loss: 0.2233 - val_accuracy: 0.9799\n",
            "Epoch 398/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.2532 - val_accuracy: 0.9769\n",
            "Epoch 399/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.1984 - val_accuracy: 0.9808\n",
            "Epoch 400/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.2174 - val_accuracy: 0.9791\n",
            "Epoch 401/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.1929 - val_accuracy: 0.9812\n",
            "Epoch 402/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.7753e-04 - accuracy: 0.9998 - val_loss: 0.2075 - val_accuracy: 0.9810\n",
            "Epoch 403/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0000e-04 - accuracy: 0.9999 - val_loss: 0.2136 - val_accuracy: 0.9798\n",
            "Epoch 404/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0028e-04 - accuracy: 0.9999 - val_loss: 0.2045 - val_accuracy: 0.9814\n",
            "Epoch 405/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.2255 - val_accuracy: 0.9791\n",
            "Epoch 406/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.2372 - val_accuracy: 0.9764\n",
            "Epoch 407/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.2166 - val_accuracy: 0.9795\n",
            "Epoch 408/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2153 - val_accuracy: 0.9804\n",
            "Epoch 409/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2228 - val_accuracy: 0.9805\n",
            "Epoch 410/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.2386 - val_accuracy: 0.9792\n",
            "Epoch 411/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2470 - val_accuracy: 0.9775\n",
            "Epoch 412/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2188 - val_accuracy: 0.9802\n",
            "Epoch 413/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.2426 - val_accuracy: 0.9789\n",
            "Epoch 414/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.2213 - val_accuracy: 0.9793\n",
            "Epoch 415/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.2311 - val_accuracy: 0.9797\n",
            "Epoch 416/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.1765e-04 - accuracy: 0.9997 - val_loss: 0.2275 - val_accuracy: 0.9806\n",
            "Epoch 417/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.2434 - val_accuracy: 0.9784\n",
            "Epoch 418/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2263 - val_accuracy: 0.9809\n",
            "Epoch 419/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.2585 - val_accuracy: 0.9762\n",
            "Epoch 420/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.2121 - val_accuracy: 0.9805\n",
            "Epoch 421/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.2446 - val_accuracy: 0.9785\n",
            "Epoch 422/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.2275 - val_accuracy: 0.9802\n",
            "Epoch 423/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2271 - val_accuracy: 0.9785\n",
            "Epoch 424/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1965 - val_accuracy: 0.9813\n",
            "Epoch 425/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5511e-04 - accuracy: 0.9998 - val_loss: 0.2135 - val_accuracy: 0.9803\n",
            "Epoch 426/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.2085 - val_accuracy: 0.9815\n",
            "Epoch 427/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.2088 - val_accuracy: 0.9800\n",
            "Epoch 428/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2582 - val_accuracy: 0.9777\n",
            "Epoch 429/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.2383 - val_accuracy: 0.9808\n",
            "Epoch 430/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.2224 - val_accuracy: 0.9806\n",
            "Epoch 431/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.2155 - val_accuracy: 0.9808\n",
            "Epoch 432/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.2059 - val_accuracy: 0.9785\n",
            "Epoch 433/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.2269 - val_accuracy: 0.9787\n",
            "Epoch 434/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2124 - val_accuracy: 0.9802\n",
            "Epoch 435/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2210 - val_accuracy: 0.9799\n",
            "Epoch 436/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.7395e-04 - accuracy: 0.9997 - val_loss: 0.2021 - val_accuracy: 0.9796\n",
            "Epoch 437/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.2352 - val_accuracy: 0.9804\n",
            "Epoch 438/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.2376 - val_accuracy: 0.9799\n",
            "Epoch 439/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.2337 - val_accuracy: 0.9797\n",
            "Epoch 440/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2183 - val_accuracy: 0.9807\n",
            "Epoch 441/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.8800e-04 - accuracy: 0.9998 - val_loss: 0.2289 - val_accuracy: 0.9801\n",
            "Epoch 442/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.0251e-05 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9813\n",
            "Epoch 443/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0640e-05 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9811\n",
            "Epoch 444/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.8310e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9809\n",
            "Epoch 445/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0372e-06 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9810\n",
            "Epoch 446/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7058e-06 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9810\n",
            "Epoch 447/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4778e-06 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9810\n",
            "Epoch 448/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.3076e-06 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9810\n",
            "Epoch 449/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1721e-06 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9811\n",
            "Epoch 450/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.0564e-06 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9811\n",
            "Epoch 451/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.5868e-07 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9811\n",
            "Epoch 452/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.7422e-07 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9812\n",
            "Epoch 453/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.0061e-07 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9811\n",
            "Epoch 454/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.3408e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9811\n",
            "Epoch 455/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7662e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9812\n",
            "Epoch 456/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.2407e-07 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9811\n",
            "Epoch 457/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.7536e-07 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9811\n",
            "Epoch 458/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.3092e-07 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9810\n",
            "Epoch 459/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.9111e-07 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9812\n",
            "Epoch 460/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.5395e-07 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9812\n",
            "Epoch 461/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1989e-07 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9812\n",
            "Epoch 462/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.8859e-07 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9812\n",
            "Epoch 463/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.5911e-07 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9812\n",
            "Epoch 464/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3231e-07 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9812\n",
            "Epoch 465/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0769e-07 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9812\n",
            "Epoch 466/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8480e-07 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9812\n",
            "Epoch 467/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6365e-07 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9812\n",
            "Epoch 468/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4397e-07 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9813\n",
            "Epoch 469/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2584e-07 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9813\n",
            "Epoch 470/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0871e-07 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9813\n",
            "Epoch 471/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9313e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9814\n",
            "Epoch 472/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7844e-07 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9813\n",
            "Epoch 473/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6499e-07 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9813\n",
            "Epoch 474/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.5222e-07 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9813\n",
            "Epoch 475/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.4057e-07 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9813\n",
            "Epoch 476/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.2943e-07 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9813\n",
            "Epoch 477/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1933e-07 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9813\n",
            "Epoch 478/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1007e-07 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9812\n",
            "Epoch 479/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0128e-07 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9812\n",
            "Epoch 480/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.3251e-08 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9813\n",
            "Epoch 481/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.5649e-08 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9813\n",
            "Epoch 482/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.8805e-08 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9814\n",
            "Epoch 483/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.2411e-08 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9814\n",
            "Epoch 484/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.6473e-08 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9814\n",
            "Epoch 485/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.1013e-08 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9815\n",
            "Epoch 486/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5887e-08 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9815\n",
            "Epoch 487/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.1278e-08 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9815\n",
            "Epoch 488/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.7024e-08 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9815\n",
            "Epoch 489/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2965e-08 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9815\n",
            "Epoch 490/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9472e-08 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9814\n",
            "Epoch 491/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.6128e-08 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9815\n",
            "Epoch 492/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3081e-08 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9816\n",
            "Epoch 493/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0335e-08 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9816\n",
            "Epoch 494/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7724e-08 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9818\n",
            "Epoch 495/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5292e-08 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9817\n",
            "Epoch 496/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3168e-08 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9818\n",
            "Epoch 497/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1191e-08 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9818\n",
            "Epoch 498/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9419e-08 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9818\n",
            "Epoch 499/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.7734e-08 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9818\n",
            "Epoch 500/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.6254e-08 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9819\n",
            "Epoch 501/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.4844e-08 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9820\n",
            "Epoch 502/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.3610e-08 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9818\n",
            "Epoch 503/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.2477e-08 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9819\n",
            "Epoch 504/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1384e-08 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9819\n",
            "Epoch 505/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0461e-08 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9820\n",
            "Epoch 506/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.5765e-09 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9819\n",
            "Epoch 507/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.8016e-09 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9819\n",
            "Epoch 508/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.0367e-09 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9819\n",
            "Epoch 509/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.4327e-09 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9819\n",
            "Epoch 510/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7989e-09 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9819\n",
            "Epoch 511/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.2644e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9818\n",
            "Epoch 512/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.7320e-09 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9819\n",
            "Epoch 513/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.3167e-09 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9818\n",
            "Epoch 514/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.8876e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9818\n",
            "Epoch 515/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.5002e-09 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9818\n",
            "Epoch 516/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1584e-09 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9817\n",
            "Epoch 517/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.8306e-09 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9819\n",
            "Epoch 518/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5266e-09 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9819\n",
            "Epoch 519/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2643e-09 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9819\n",
            "Epoch 520/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0319e-09 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9819\n",
            "Epoch 521/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8292e-09 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9819\n",
            "Epoch 522/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6186e-09 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9819\n",
            "Epoch 523/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4438e-09 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9818\n",
            "Epoch 524/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2312e-09 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9818\n",
            "Epoch 525/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1060e-09 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9817\n",
            "Epoch 526/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.9372e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9818\n",
            "Epoch 527/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8299e-09 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9818\n",
            "Epoch 528/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.7126e-09 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9819\n",
            "Epoch 529/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.6193e-09 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9819\n",
            "Epoch 530/1000\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 1.5318e-09 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9818\n",
            "Epoch 531/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.4484e-09 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9818\n",
            "Epoch 532/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.3729e-09 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9818\n",
            "Epoch 533/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.3073e-09 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9818\n",
            "Epoch 534/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1961e-09 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9818\n",
            "Epoch 535/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1365e-09 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9818\n",
            "Epoch 536/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0629e-09 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9818\n",
            "Epoch 537/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0272e-09 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9818\n",
            "Epoch 538/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2333 - val_accuracy: 0.9818\n",
            "Epoch 539/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.0599e-10 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9819\n",
            "Epoch 540/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.6824e-10 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9819\n",
            "Epoch 541/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.0665e-10 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9819\n",
            "Epoch 542/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.7287e-10 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9819\n",
            "Epoch 543/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9818\n",
            "Epoch 544/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.1128e-10 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9818\n",
            "Epoch 545/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.5764e-10 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9819\n",
            "Epoch 546/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.4373e-10 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9819\n",
            "Epoch 547/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9818\n",
            "Epoch 548/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9818\n",
            "Epoch 549/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9818\n",
            "Epoch 550/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.1856e-10 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9818\n",
            "Epoch 551/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9818\n",
            "Epoch 552/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.8677e-10 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9818\n",
            "Epoch 553/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9818\n",
            "Epoch 554/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.3909e-10 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9818\n",
            "Epoch 555/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2518e-10 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9818\n",
            "Epoch 556/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1127e-10 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9818\n",
            "Epoch 557/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0730e-10 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9818\n",
            "Epoch 558/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.8147e-10 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9818\n",
            "Epoch 559/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7352e-10 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9818\n",
            "Epoch 560/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5167e-10 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9818\n",
            "Epoch 561/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4372e-10 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9818\n",
            "Epoch 562/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3975e-10 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9818\n",
            "Epoch 563/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2783e-10 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9818\n",
            "Epoch 564/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9819\n",
            "Epoch 565/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2783e-10 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9819\n",
            "Epoch 566/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.0597e-10 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9819\n",
            "Epoch 567/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9819\n",
            "Epoch 568/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9819\n",
            "Epoch 569/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.9008e-10 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9819\n",
            "Epoch 570/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9819\n",
            "Epoch 571/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8014e-10 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9819\n",
            "Epoch 572/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8014e-10 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9819\n",
            "Epoch 573/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7418e-10 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9820\n",
            "Epoch 574/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6623e-10 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9819\n",
            "Epoch 575/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6425e-10 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9820\n",
            "Epoch 576/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7617e-10 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9820\n",
            "Epoch 577/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4835e-10 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9820\n",
            "Epoch 578/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9820\n",
            "Epoch 579/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9819\n",
            "Epoch 580/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.6027e-10 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9819\n",
            "Epoch 581/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4041e-10 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9819\n",
            "Epoch 582/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.5630e-10 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9819\n",
            "Epoch 583/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6027e-10 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9819\n",
            "Epoch 584/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3643e-10 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9819\n",
            "Epoch 585/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9819\n",
            "Epoch 586/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3246e-10 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9819\n",
            "Epoch 587/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4438e-10 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9819\n",
            "Epoch 588/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9820\n",
            "Epoch 589/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5431e-10 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9820\n",
            "Epoch 590/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2848e-10 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9822\n",
            "Epoch 591/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3444e-10 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9822\n",
            "Epoch 592/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4041e-10 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9821\n",
            "Epoch 593/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9822\n",
            "Epoch 594/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9823\n",
            "Epoch 595/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9823\n",
            "Epoch 596/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2650e-10 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9823\n",
            "Epoch 597/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9823\n",
            "Epoch 598/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2650e-10 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9823\n",
            "Epoch 599/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9823\n",
            "Epoch 600/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0862e-10 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9823\n",
            "Epoch 601/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2451e-10 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9823\n",
            "Epoch 602/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1656e-10 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9823\n",
            "Epoch 603/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9823\n",
            "Epoch 604/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0464e-10 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9822\n",
            "Epoch 605/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3246e-10 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9822\n",
            "Epoch 606/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.1855e-10 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9822\n",
            "Epoch 607/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.1656e-10 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9822\n",
            "Epoch 608/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1855e-10 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9822\n",
            "Epoch 609/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2451e-10 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9822\n",
            "Epoch 610/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9822\n",
            "Epoch 611/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2848e-10 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9821\n",
            "Epoch 612/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1259e-10 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9822\n",
            "Epoch 613/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2451e-10 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9821\n",
            "Epoch 614/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1259e-10 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9822\n",
            "Epoch 615/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0862e-10 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9823\n",
            "Epoch 616/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1656e-10 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9821\n",
            "Epoch 617/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1656e-10 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9822\n",
            "Epoch 618/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.0862e-10 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9821\n",
            "Epoch 619/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.2054e-10 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9821\n",
            "Epoch 620/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.2848e-10 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9822\n",
            "Epoch 621/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9823\n",
            "Epoch 622/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2650e-10 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9822\n",
            "Epoch 623/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9822\n",
            "Epoch 624/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1259e-10 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9821\n",
            "Epoch 625/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3444e-10 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9822\n",
            "Epoch 626/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.1656e-10 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9822\n",
            "Epoch 627/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9822\n",
            "Epoch 628/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2650e-10 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9822\n",
            "Epoch 629/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9822\n",
            "Epoch 630/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9822\n",
            "Epoch 631/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1855e-10 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9822\n",
            "Epoch 632/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9820\n",
            "Epoch 633/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2451e-10 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9821\n",
            "Epoch 634/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2848e-10 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9820\n",
            "Epoch 635/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9821\n",
            "Epoch 636/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2848e-10 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9820\n",
            "Epoch 637/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4041e-10 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9820\n",
            "Epoch 638/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4239e-10 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9820\n",
            "Epoch 639/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2451e-10 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9820\n",
            "Epoch 640/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3444e-10 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9820\n",
            "Epoch 641/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3444e-10 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9820\n",
            "Epoch 642/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9819\n",
            "Epoch 643/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2252e-10 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9819\n",
            "Epoch 644/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9818\n",
            "Epoch 645/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2054e-10 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9818\n",
            "Epoch 646/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.3246e-10 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9818\n",
            "Epoch 647/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.4835e-10 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9818\n",
            "Epoch 648/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4041e-10 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9819\n",
            "Epoch 649/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4637e-10 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9819\n",
            "Epoch 650/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9819\n",
            "Epoch 651/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3444e-10 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9820\n",
            "Epoch 652/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5034e-10 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9820\n",
            "Epoch 653/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3444e-10 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9820\n",
            "Epoch 654/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6226e-10 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9820\n",
            "Epoch 655/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3842e-10 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9821\n",
            "Epoch 656/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5630e-10 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9821\n",
            "Epoch 657/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4041e-10 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9821\n",
            "Epoch 658/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.5233e-10 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9820\n",
            "Epoch 659/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.5630e-10 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9820\n",
            "Epoch 660/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.5829e-10 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9820\n",
            "Epoch 661/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7021e-10 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9820\n",
            "Epoch 662/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3047e-10 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9820\n",
            "Epoch 663/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7617e-10 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9820\n",
            "Epoch 664/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.6027e-10 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9820\n",
            "Epoch 665/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7219e-10 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9822\n",
            "Epoch 666/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.6425e-10 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9820\n",
            "Epoch 667/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.4239e-10 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9822\n",
            "Epoch 668/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9820\n",
            "Epoch 669/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5630e-10 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9821\n",
            "Epoch 670/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9821\n",
            "Epoch 671/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.6027e-10 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9820\n",
            "Epoch 672/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.9008e-10 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9821\n",
            "Epoch 673/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.8014e-10 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9821\n",
            "Epoch 674/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8213e-10 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9822\n",
            "Epoch 675/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7219e-10 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9820\n",
            "Epoch 676/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8213e-10 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9819\n",
            "Epoch 677/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6027e-10 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9820\n",
            "Epoch 678/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9820\n",
            "Epoch 679/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.7617e-10 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9821\n",
            "Epoch 680/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9405e-10 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9821\n",
            "Epoch 681/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.8610e-10 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9820\n",
            "Epoch 682/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9821\n",
            "Epoch 683/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7418e-10 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9820\n",
            "Epoch 684/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9821\n",
            "Epoch 685/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9820\n",
            "Epoch 686/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7617e-10 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9820\n",
            "Epoch 687/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9820\n",
            "Epoch 688/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.9604e-10 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9820\n",
            "Epoch 689/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0398e-10 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9821\n",
            "Epoch 690/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1988e-10 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9820\n",
            "Epoch 691/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0001e-10 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9820\n",
            "Epoch 692/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.9802e-10 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9820\n",
            "Epoch 693/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.8213e-10 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9820\n",
            "Epoch 694/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9819\n",
            "Epoch 695/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1789e-10 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9819\n",
            "Epoch 696/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.0597e-10 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9819\n",
            "Epoch 697/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.1988e-10 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9819\n",
            "Epoch 698/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.0001e-10 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9819\n",
            "Epoch 699/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.0001e-10 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9819\n",
            "Epoch 700/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2187e-10 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9820\n",
            "Epoch 701/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3180e-10 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9819\n",
            "Epoch 702/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.0994e-10 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9819\n",
            "Epoch 703/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1392e-10 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9820\n",
            "Epoch 704/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3180e-10 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9819\n",
            "Epoch 705/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.1392e-10 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9819\n",
            "Epoch 706/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3577e-10 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9820\n",
            "Epoch 707/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3577e-10 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9820\n",
            "Epoch 708/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3776e-10 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9819\n",
            "Epoch 709/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.2584e-10 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9819\n",
            "Epoch 710/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.3975e-10 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9820\n",
            "Epoch 711/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.3379e-10 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9820\n",
            "Epoch 712/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.2981e-10 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9820\n",
            "Epoch 713/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4173e-10 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9819\n",
            "Epoch 714/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5365e-10 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9818\n",
            "Epoch 715/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4769e-10 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9818\n",
            "Epoch 716/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.3776e-10 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9820\n",
            "Epoch 717/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4571e-10 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9819\n",
            "Epoch 718/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9817\n",
            "Epoch 719/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5961e-10 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9818\n",
            "Epoch 720/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2981e-10 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9817\n",
            "Epoch 721/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7154e-10 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9818\n",
            "Epoch 722/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.4968e-10 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9821\n",
            "Epoch 723/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.5763e-10 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9820\n",
            "Epoch 724/1000\n",
            "235/235 [==============================] - 2s 6ms/step - loss: 3.5961e-10 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9821\n",
            "Epoch 725/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.6955e-10 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9821\n",
            "Epoch 726/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.5961e-10 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9820\n",
            "Epoch 727/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5167e-10 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9821\n",
            "Epoch 728/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.6359e-10 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9822\n",
            "Epoch 729/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.5961e-10 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9820\n",
            "Epoch 730/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.6756e-10 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9820\n",
            "Epoch 731/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7352e-10 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9821\n",
            "Epoch 732/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9140e-10 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9822\n",
            "Epoch 733/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7750e-10 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9820\n",
            "Epoch 734/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0332e-10 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9820\n",
            "Epoch 735/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.8147e-10 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9822\n",
            "Epoch 736/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.7948e-10 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9820\n",
            "Epoch 737/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.9822\n",
            "Epoch 738/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.9935e-10 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9820\n",
            "Epoch 739/1000\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 3.8743e-10 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9821\n",
            "Epoch 740/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1525e-10 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9820\n",
            "Epoch 741/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0730e-10 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9820\n",
            "Epoch 742/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.2121e-10 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9821\n",
            "Epoch 743/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0134e-10 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9820\n",
            "Epoch 744/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9935e-10 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9821\n",
            "Epoch 745/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.2121e-10 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9819\n",
            "Epoch 746/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.1127e-10 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9820\n",
            "Epoch 747/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.0929e-10 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9819\n",
            "Epoch 748/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1922e-10 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9819\n",
            "Epoch 749/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9736e-10 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9818\n",
            "Epoch 750/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1127e-10 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9821\n",
            "Epoch 751/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.3511e-10 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9819\n",
            "Epoch 752/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2717e-10 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9817\n",
            "Epoch 753/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2319e-10 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9816\n",
            "Epoch 754/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.3511e-10 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9817\n",
            "Epoch 755/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.6293e-10 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9818\n",
            "Epoch 756/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.6293e-10 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9817\n",
            "Epoch 757/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.5101e-10 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9818\n",
            "Epoch 758/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.4505e-10 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9815\n",
            "Epoch 759/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.9074e-10 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9816\n",
            "Epoch 760/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.6293e-10 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9815\n",
            "Epoch 761/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9816\n",
            "Epoch 762/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9814\n",
            "Epoch 763/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.9869e-10 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9817\n",
            "Epoch 764/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.6492e-10 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9815\n",
            "Epoch 765/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.8081e-10 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9814\n",
            "Epoch 766/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.8876e-10 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9814\n",
            "Epoch 767/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.9472e-10 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9813\n",
            "Epoch 768/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9815\n",
            "Epoch 769/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.7286e-10 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9815\n",
            "Epoch 770/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.9671e-10 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9814\n",
            "Epoch 771/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.8280e-10 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9814\n",
            "Epoch 772/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.8280e-10 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9814\n",
            "Epoch 773/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9814\n",
            "Epoch 774/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9814\n",
            "Epoch 775/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9814\n",
            "Epoch 776/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.9273e-10 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9814\n",
            "Epoch 777/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9815\n",
            "Epoch 778/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 5.1459e-10 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9815\n",
            "Epoch 779/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 5.5035e-10 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9813\n",
            "Epoch 780/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.2849e-10 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9814\n",
            "Epoch 781/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9813\n",
            "Epoch 782/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9813\n",
            "Epoch 783/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9813\n",
            "Epoch 784/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.3843e-10 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9814\n",
            "Epoch 785/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.3843e-10 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9814\n",
            "Epoch 786/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9815\n",
            "Epoch 787/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.1856e-10 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9813\n",
            "Epoch 788/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5432e-10 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9814\n",
            "Epoch 789/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9814\n",
            "Epoch 790/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9810\n",
            "Epoch 791/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.5035e-10 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9812\n",
            "Epoch 792/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 5.6028e-10 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9812\n",
            "Epoch 793/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.7817e-10 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9812\n",
            "Epoch 794/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.5830e-10 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9810\n",
            "Epoch 795/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.6227e-10 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9810\n",
            "Epoch 796/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.7817e-10 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9808\n",
            "Epoch 797/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.8413e-10 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9810\n",
            "Epoch 798/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9808\n",
            "Epoch 799/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9811\n",
            "Epoch 800/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9811\n",
            "Epoch 801/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.8413e-10 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9809\n",
            "Epoch 802/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.6227e-10 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9808\n",
            "Epoch 803/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.1790e-10 - accuracy: 1.0000 - val_loss: 0.3153 - val_accuracy: 0.9809\n",
            "Epoch 804/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.0598e-10 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9810\n",
            "Epoch 805/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 5.6823e-10 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 0.9809\n",
            "Epoch 806/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.9406e-10 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9810\n",
            "Epoch 807/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9809\n",
            "Epoch 808/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.9803e-10 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9809\n",
            "Epoch 809/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9809\n",
            "Epoch 810/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.9809\n",
            "Epoch 811/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.1591e-10 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9808\n",
            "Epoch 812/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.3380e-10 - accuracy: 1.0000 - val_loss: 0.3185 - val_accuracy: 0.9807\n",
            "Epoch 813/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.3777e-10 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9808\n",
            "Epoch 814/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9808\n",
            "Epoch 815/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9806\n",
            "Epoch 816/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.2784e-10 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9807\n",
            "Epoch 817/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.5764e-10 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9807\n",
            "Epoch 818/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.6161e-10 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9806\n",
            "Epoch 819/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9807\n",
            "Epoch 820/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.6559e-10 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9807\n",
            "Epoch 821/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9805\n",
            "Epoch 822/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.7155e-10 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9806\n",
            "Epoch 823/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9806\n",
            "Epoch 824/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7155e-10 - accuracy: 1.0000 - val_loss: 0.3239 - val_accuracy: 0.9807\n",
            "Epoch 825/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.6956e-10 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9805\n",
            "Epoch 826/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.4174e-10 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9805\n",
            "Epoch 827/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.3976e-10 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9804\n",
            "Epoch 828/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.7353e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9805\n",
            "Epoch 829/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.8545e-10 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9805\n",
            "Epoch 830/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9803\n",
            "Epoch 831/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.3380e-10 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9804\n",
            "Epoch 832/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.2718e-10 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9804\n",
            "Epoch 833/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.4307e-10 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9803\n",
            "Epoch 834/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9802\n",
            "Epoch 835/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7949e-10 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9804\n",
            "Epoch 836/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9802\n",
            "Epoch 837/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.2320e-10 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9802\n",
            "Epoch 838/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.8943e-10 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9804\n",
            "Epoch 839/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.1923e-10 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9802\n",
            "Epoch 840/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9801\n",
            "Epoch 841/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.2916e-10 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9803\n",
            "Epoch 842/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9803\n",
            "Epoch 843/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.5301e-10 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9803\n",
            "Epoch 844/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9801\n",
            "Epoch 845/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.0864e-10 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9801\n",
            "Epoch 846/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.6095e-10 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9802\n",
            "Epoch 847/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9801\n",
            "Epoch 848/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.6294e-10 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9798\n",
            "Epoch 849/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.9075e-10 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9799\n",
            "Epoch 850/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.3645e-10 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9800\n",
            "Epoch 851/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.2453e-10 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9800\n",
            "Epoch 852/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.0665e-10 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9797\n",
            "Epoch 853/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.6228e-10 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9801\n",
            "Epoch 854/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.5235e-10 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9800\n",
            "Epoch 855/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.7486e-10 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9800\n",
            "Epoch 856/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 9.0202e-10 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9803\n",
            "Epoch 857/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.7685e-10 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9801\n",
            "Epoch 858/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.8479e-10 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9800\n",
            "Epoch 859/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.8016e-10 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9797\n",
            "Epoch 860/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.2850e-10 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9797\n",
            "Epoch 861/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.1261e-10 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9798\n",
            "Epoch 862/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.4771e-10 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9799\n",
            "Epoch 863/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.8612e-10 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9799\n",
            "Epoch 864/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.7023e-10 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9801\n",
            "Epoch 865/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.6029e-10 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9801\n",
            "Epoch 866/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.2785e-10 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9798\n",
            "Epoch 867/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.5235e-10 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9801\n",
            "Epoch 868/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.5632e-10 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9798\n",
            "Epoch 869/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 9.1990e-10 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9801\n",
            "Epoch 870/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.2785e-10 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9800\n",
            "Epoch 871/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.1394e-10 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9798\n",
            "Epoch 872/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.4970e-10 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9798\n",
            "Epoch 873/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.1990e-10 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9797\n",
            "Epoch 874/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9799\n",
            "Epoch 875/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.5765e-10 - accuracy: 1.0000 - val_loss: 0.3451 - val_accuracy: 0.9798\n",
            "Epoch 876/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.8944e-10 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9799\n",
            "Epoch 877/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0272e-09 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9796\n",
            "Epoch 878/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.5765e-10 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9798\n",
            "Epoch 879/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0014e-09 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9798\n",
            "Epoch 880/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.0371e-09 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9798\n",
            "Epoch 881/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 9.5765e-10 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9801\n",
            "Epoch 882/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.0928e-09 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9800\n",
            "Epoch 883/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9953 - val_loss: 0.4020 - val_accuracy: 0.9764\n",
            "Epoch 884/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.3078 - val_accuracy: 0.9793\n",
            "Epoch 885/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.2798 - val_accuracy: 0.9815\n",
            "Epoch 886/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.5138e-04 - accuracy: 0.9999 - val_loss: 0.2817 - val_accuracy: 0.9813\n",
            "Epoch 887/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1730e-04 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9818\n",
            "Epoch 888/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.3690e-06 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9817\n",
            "Epoch 889/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1502e-06 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9816\n",
            "Epoch 890/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4732e-06 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9814\n",
            "Epoch 891/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2370e-06 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9813\n",
            "Epoch 892/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.0730e-06 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9813\n",
            "Epoch 893/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 9.4616e-07 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9814\n",
            "Epoch 894/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.4593e-07 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9814\n",
            "Epoch 895/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.6106e-07 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9814\n",
            "Epoch 896/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.9013e-07 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9814\n",
            "Epoch 897/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.2732e-07 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9814\n",
            "Epoch 898/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.7239e-07 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9814\n",
            "Epoch 899/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.2436e-07 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9814\n",
            "Epoch 900/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.8035e-07 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9814\n",
            "Epoch 901/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.4139e-07 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9814\n",
            "Epoch 902/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.0587e-07 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9815\n",
            "Epoch 903/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.7374e-07 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9815\n",
            "Epoch 904/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.4492e-07 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9816\n",
            "Epoch 905/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.1799e-07 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9816\n",
            "Epoch 906/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.9318e-07 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9816\n",
            "Epoch 907/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.6996e-07 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9817\n",
            "Epoch 908/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 2.4912e-07 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9817\n",
            "Epoch 909/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.2944e-07 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9817\n",
            "Epoch 910/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.1184e-07 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9817\n",
            "Epoch 911/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.9574e-07 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9817\n",
            "Epoch 912/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.7960e-07 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9818\n",
            "Epoch 913/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.6556e-07 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9817\n",
            "Epoch 914/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.5289e-07 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9817\n",
            "Epoch 915/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.4074e-07 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9818\n",
            "Epoch 916/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2985e-07 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9818\n",
            "Epoch 917/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.1981e-07 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9818\n",
            "Epoch 918/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.1026e-07 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9818\n",
            "Epoch 919/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.0170e-07 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9819\n",
            "Epoch 920/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.3645e-08 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9819\n",
            "Epoch 921/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.6219e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9819\n",
            "Epoch 922/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.9337e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9818\n",
            "Epoch 923/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.2844e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9820\n",
            "Epoch 924/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.7211e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9820\n",
            "Epoch 925/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.1760e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9820\n",
            "Epoch 926/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.6944e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9820\n",
            "Epoch 927/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.2378e-08 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9819\n",
            "Epoch 928/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.8317e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9819\n",
            "Epoch 929/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.4445e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9818\n",
            "Epoch 930/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0895e-08 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9818\n",
            "Epoch 931/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.7652e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9818\n",
            "Epoch 932/1000\n",
            "235/235 [==============================] - 2s 6ms/step - loss: 3.4582e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9818\n",
            "Epoch 933/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.1948e-08 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9818\n",
            "Epoch 934/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.9176e-08 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9822\n",
            "Epoch 935/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.6955e-08 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9820\n",
            "Epoch 936/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.4795e-08 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9820\n",
            "Epoch 937/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2779e-08 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9822\n",
            "Epoch 938/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.0931e-08 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9822\n",
            "Epoch 939/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.9246e-08 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9822\n",
            "Epoch 940/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.7689e-08 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9823\n",
            "Epoch 941/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.6254e-08 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9824\n",
            "Epoch 942/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.4897e-08 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9823\n",
            "Epoch 943/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.3745e-08 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9823\n",
            "Epoch 944/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.2634e-08 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9822\n",
            "Epoch 945/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.1539e-08 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9822\n",
            "Epoch 946/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.0586e-08 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9823\n",
            "Epoch 947/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.7215e-09 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9823\n",
            "Epoch 948/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.9447e-09 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9822\n",
            "Epoch 949/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.2215e-09 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9823\n",
            "Epoch 950/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.5479e-09 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9823\n",
            "Epoch 951/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.9122e-09 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9821\n",
            "Epoch 952/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.3598e-09 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9821\n",
            "Epoch 953/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.8571e-09 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9821\n",
            "Epoch 954/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.4022e-09 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9821\n",
            "Epoch 955/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.9631e-09 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9821\n",
            "Epoch 956/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.5617e-09 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9821\n",
            "Epoch 957/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.1982e-09 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9821\n",
            "Epoch 958/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 3.8664e-09 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9821\n",
            "Epoch 959/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.5425e-09 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9820\n",
            "Epoch 960/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.2663e-09 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9821\n",
            "Epoch 961/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 3.0319e-09 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9822\n",
            "Epoch 962/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.7855e-09 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9821\n",
            "Epoch 963/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.5789e-09 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9821\n",
            "Epoch 964/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.3782e-09 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9822\n",
            "Epoch 965/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 2.2193e-09 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9822\n",
            "Epoch 966/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 2.0762e-09 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9821\n",
            "Epoch 967/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.8736e-09 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9821\n",
            "Epoch 968/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.7762e-09 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9821\n",
            "Epoch 969/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.6510e-09 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9822\n",
            "Epoch 970/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 1.5318e-09 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9822\n",
            "Epoch 971/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.4285e-09 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9822\n",
            "Epoch 972/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 1.3212e-09 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9822\n",
            "Epoch 973/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.2259e-09 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9822\n",
            "Epoch 974/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.1623e-09 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9822\n",
            "Epoch 975/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0590e-09 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9821\n",
            "Epoch 976/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 1.0073e-09 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9822\n",
            "Epoch 977/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 9.4771e-10 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9822\n",
            "Epoch 978/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 8.7619e-10 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9823\n",
            "Epoch 979/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.4440e-10 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9823\n",
            "Epoch 980/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.9473e-10 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9824\n",
            "Epoch 981/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.4506e-10 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9824\n",
            "Epoch 982/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9823\n",
            "Epoch 983/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9825\n",
            "Epoch 984/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.3777e-10 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9827\n",
            "Epoch 985/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.0598e-10 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9825\n",
            "Epoch 986/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.0598e-10 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 0.9826\n",
            "Epoch 987/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.3445e-10 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9825\n",
            "Epoch 988/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9826\n",
            "Epoch 989/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9825\n",
            "Epoch 990/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9825\n",
            "Epoch 991/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.7088e-10 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9825\n",
            "Epoch 992/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9825\n",
            "Epoch 993/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.5101e-10 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9825\n",
            "Epoch 994/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.2319e-10 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9825\n",
            "Epoch 995/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.2121e-10 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9825\n",
            "Epoch 996/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.1525e-10 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9826\n",
            "Epoch 997/1000\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 4.1723e-10 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9825\n",
            "Epoch 998/1000\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.1127e-10 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9822\n",
            "Epoch 999/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.0730e-10 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9823\n",
            "Epoch 1000/1000\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 3.9935e-10 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if we dont set validation_data on model we can evalute by this\n",
        "model.evaluate(test_features,test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFwBI7QokJfN",
        "outputId": "da2b4851-0330-458e-f34e-09d06ff815ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2862 - accuracy: 0.9822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28618931770324707, 0.982200026512146]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict ü§ñ"
      ],
      "metadata": {
        "id": "xylGCeN4zwST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#choose one of data in test for predict by model(number 100 from test data)\n",
        "img = test_features[100]\n",
        "print(test_labels[100])\n",
        "plt.gray()\n",
        "plt.imshow(img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "1HkKm_OJvZ85",
        "outputId": "816462ba-ad3a-4d38-b436-f86846a1766b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79c114762200>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.predict(img) is wrong because its 28*28 and expect -1,784(28*28)\n",
        "model.predict(np.reshape(img,(-1,784)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_Xf_w_x1Rv3",
        "outputId": "20e8da08-b67b-42ac-b208-225eb8fa278f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1341641e-31, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 8.5099829e-36, 1.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#elemane 6om 1 shode pas its 6"
      ],
      "metadata": {
        "id": "uivLderL2VP5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}